{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y_data = pd.DataFrame(iris.target, columns=['label'])\n",
    "y_data['species'] = y_data['label'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'}).astype('category')\n",
    "\n",
    "# Data preparation\n",
    "test_frac = 1/3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data['label'], test_size=test_frac, shuffle=True, stratify=y_data['label'])\n",
    "\n",
    "# Inspection of the training set\n",
    "# Short summary of training set\n",
    "print(\"Summary of the training set:\")\n",
    "print(X_train.describe())\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = X_train.corr()\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualization\n",
    "print(\"Visualization:\")\n",
    "for feature in X_train.columns:\n",
    "    sns.boxplot(x=y_train, y=X_train[feature])\n",
    "    plt.title(f'Boxplot of {feature} grouped by species')\n",
    "    plt.show()\n",
    "\n",
    "sns.pairplot(X_train.join(y_train, how='outer'), hue='label')\n",
    "plt.title('Pairplot of features colored by species')\n",
    "plt.show()\n",
    "\n",
    "# Classification with KNN\n",
    "# Classification using all the features\n",
    "# Create a baseline k-NN classifier with k=3\n",
    "knn_classifier = KNN(n_neighbors=3)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Classification errors\n",
    "train_error_predict = knn_classifier.predict(X_train)\n",
    "train_error = 1 - knn_classifier.score(X_train, y_train)\n",
    "print(\"Classification error on training set (using predict method):\", train_error)\n",
    "\n",
    "train_score = knn_classifier.score(X_train, y_train)\n",
    "print(\"Classification error on training set (using score method):\", 1 - train_score)\n",
    "\n",
    "test_error = 1 - knn_classifier.score(X_test, y_test)\n",
    "print(\"Classification error on test set:\", test_error)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, knn_classifier.predict(X_test))\n",
    "print(\"Confusion matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Classification using only 2 features\n",
    "features_2D = ['petal length (cm)', 'sepal width (cm)']\n",
    "X_train_2D = X_train[features_2D]\n",
    "\n",
    "knn_classifier_2D = KNN(n_neighbors=3)\n",
    "knn_classifier_2D.fit(X_train_2D, y_train)\n",
    "\n",
    "# Decision boundary\n",
    "# Mesh the input space\n",
    "h = .02\n",
    "x_min, x_max = X_train_2D[features_2D[0]].min() - 1, X_train_2D[features_2D[0]].max() + 1\n",
    "y_min, y_max = X_train_2D[features_2D[1]].min() - 1, X_train_2D[features_2D[1]].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "mesh_data = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# Predict labels of the mesh's nodes\n",
    "y_pred_mesh = knn_classifier_2D.predict(mesh_data)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.figure()\n",
    "plt.contourf(xx, yy, y_pred_mesh.reshape(xx.shape), alpha=0.8)\n",
    "plt.scatter(X_train_2D[features_2D[0]], X_train_2D[features_2D[1]], c=y_train, edgecolors='k', s=20)\n",
    "plt.title(\"Decision boundary of k-NN classifier with 2 features\")\n",
    "plt.xlabel(features_2D[0])\n",
    "plt.ylabel(features_2D[1])\n",
    "plt.show()\n",
    "\n",
    "# Tune the k parameter manually\n",
    "X_train_small, X_valid, y_train_small, y_valid = train_test_split(X_train_2D, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model for different values of k and predict on the validation set\n",
    "validation_errors = []\n",
    "for k in range(1, 21):\n",
    "    knn_classifier = KNN(n_neighbors=k)\n",
    "    knn_classifier.fit(X_train_small, y_train_small)\n",
    "    validation_errors.append(1 - knn_classifier.score(X_valid, y_valid))\n",
    "\n",
    "best_k = np.argmin(validation_errors) + 1\n",
    "print(\"Best k value found using manual tuning:\", best_k)\n",
    "\n",
    "# Bonus: with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = {'n_neighbors': np.arange(1, 20), 'weights': ['uniform', 'distance']}\n",
    "knn_gs = GridSearchCV(estimator=KNN(), param_grid=grid, cv=5, scoring='accuracy')\n",
    "knn_gs.fit(X_train_2D, y_train)\n",
    "print(\"Best parameters found using GridSearchCV:\", knn_gs.best_params_)\n",
    "print(\"Test error with best parameters:\", 1 - knn_gs.best_estimator_.score(X_test[features_2D], y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f8f1dc41537c785e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
